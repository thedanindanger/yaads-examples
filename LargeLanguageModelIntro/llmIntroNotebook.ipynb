{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "## Popular Models:\n",
    "- ChatGPT (what everyone is using): https://chat.openai.com/auth/login\n",
    "- OpenAI playground (what you can use when ChatGPT is down): https://platform.openai.com/playground\n",
    "- LLaMa repo: https://github.com/facebookresearch/llama\n",
    "- Alpaca repo: https://github.com/tatsu-lab/stanford_alpaca\n",
    "- BLOOM repo: https://huggingface.co/bigscience/bloom forked from https://github.com/bigscience-workshop/Megatron-DeepSpeed \n",
    "- Bard (on waitlist as of March 2023): https://bard.google.com/ \n",
    "\n",
    "## Helpful Links\n",
    "- How GPT (and LLMs generally) work: https://dugas.ch/artificial_curiosity/GPT_architecture.html \n",
    "- Colab notebook to train own LLM: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb\n",
    "- HuggingFace demo with different LLMs: https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "## ChatGPT (OpenAI) Response to \"Current State of Large Language Models in 2023\"\n",
    "As of 2023, large language models have continued to evolve and advance in various ways, with several notable developments and applications:\n",
    "\n",
    "1. Continual improvement in model size and performance: Language models have continued to increase in size and complexity, with recent models such as GPT-4 and T5 exceeding trillions of parameters. These models have achieved state-of-the-art results on a range of language tasks, including language generation, translation, and understanding.\n",
    "\n",
    "2. Expansion of multilingual capabilities: Many large language models are now trained to understand and generate text in multiple languages, including low-resource languages, making them more accessible and useful for a wider range of users worldwide.\n",
    "\n",
    "3. Enhanced fine-tuning capabilities: Fine-tuning allows for the adaptation of pre-trained models to specific domains or tasks, such as conversational AI, question answering, and sentiment analysis. Recent advances in fine-tuning techniques have made it easier to fine-tune models for specific applications with fewer training examples.\n",
    "\n",
    "4. Advancements in model compression and optimization: As models grow larger, there is a need to compress and optimize them for efficient deployment in resource-constrained environments. Recent techniques such as pruning, distillation, and quantization have made it possible to reduce the size and computational cost of large models without significant loss in performance.\n",
    "\n",
    "5. Increased attention to ethical considerations: With the growing influence of large language models, there has been increasing attention to ethical considerations surrounding their use, including issues related to bias, privacy, and transparency. Researchers and practitioners are working to address these concerns through improved data collection, model training, and deployment practices.\n",
    "\n",
    "Overall, large language models have continued to push the boundaries of natural language processing and have demonstrated significant potential for a wide range of applications. However, ongoing efforts are needed to ensure their responsible and ethical use.\n",
    "\n",
    "\n",
    "\n",
    "### Analysis of response\n",
    "This response is a great example of why ChatGPT isn't going to replace people directly, it (and other Large Language Models) need fine tuning for specific use cases.\n",
    "\n",
    "This is a 'vanilla' response. It's so generic that it says effectively nothing. If someone was unfamiliar with LLM and Natural Language Processing/Understanding, they may feel this ChatGPT's response is suitable. They may even publish an article about it and present themselves as an expert.\n",
    "\n",
    "Unfortunately, such articles are then used to further train LLMs, reinforcing this 'Cycle of Stupidity'(tm). \n",
    "\n",
    "### Split in LLMs Business Models - A lot of a little or a little of a lot\n",
    "Broadly speaking, in technology there are two business models:\n",
    "1. Get a lot of users by charging a little-to-nothing for the service\n",
    "2. Charge a little number of users a lot of money\n",
    "\n",
    "ChatGPT and it's ilk are type 1. Type 2 are not discussed generally because it requires a lot of work, and they need to be private.\n",
    "\n",
    "The problem here is two fold. First, the more accessible type 1 models optimize toward broad appeal. Meaning they will produce results understandable and applicable for the general population. Second, the more money and time a business can dedicate to creating its own AI routines, the more competitive advantage it gains.\n",
    "\n",
    "We now have a situation where AI routines are created by highly specialized engineers, but there is little opportunity for new engineers to learn how the routines work. Leading to 'black box' operations similar to what we saw when Enterprise Systems first started in the 80s.\n",
    "\n",
    "Additionally, the average person will think AI is as dumb if not dumber then they are. This could create a false sense of security. That said, as long as non-technical people are in charge of businesses decisions related to AI, they will also tend toward broadly appealing AI outcomes, so we likely won't see large scale AI implementation in major firms for quite some time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Large Language Models (LLMs) Work\n",
    "Great summary here: https://dugas.ch/artificial_curiosity/GPT_architecture.html Although focusing on ChatGPT, the concepts are applied in most LLMs.\n",
    "\n",
    "## General process:\n",
    "Any text based Deep Learning, AI, Machine Learning process needs to translate text into numbers, predict numeric outputs from numeric input, then translate the output numbers back into text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    A(Block Text) -->|Tokenizing| B(Text as Small-Phrases)\n",
    "    B -->|Encoding + Embedding| C(Phrases as Numeric Input Matrix)\n",
    "    C -->|Neural Network Operations| D(Predicted Numeric Output Matrix)\n",
    "    D -->|Decoding| E(Predicted Output Text)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tokenizing: Split large text into small terms/phrases\n",
    "This article is a fantastic introduction to tokenizing, encoding, and embedding: https://datajenius.com/2022/03/13/a-deep-dive-into-nlp-tokenization-encoding-word-embeddings-sentence-embeddings-word2vec-bert/ \n",
    "\n",
    "\"Tokenizing\" is essentially a fancy way to say we split large text into smaller parts.\n",
    "\n",
    "## Encoding and Embedding: Make terms in to numbers\n",
    "Generally, Artifical Intelligence / Machine Learning processes are all extensions of a few statistical / linear algebra techniques.\n",
    "\n",
    "Advancements in AI/ML are often faster ways to apply said techniques and novel ways to transform non-numerical data into numerical data.\n",
    "\n",
    "The exact processes used are not that important to understand in practice, but conceptually are not very difficult to learn, and provide the foundation for many AI/ML operations, so I highly encourage it. \n",
    "\n",
    "Again, please read this article, so much will make sense once you get through it: https://datajenius.com/2022/03/13/a-deep-dive-into-nlp-tokenization-encoding-word-embeddings-sentence-embeddings-word2vec-bert/ \n",
    "\n",
    "## Neural Network / 'Traditional' Machine Learning Operations:\n",
    "To understand the foundations of Neural Networks and Deep Learning I highly encourage you to take these courses and complete all exercises: https://www.coursera.org/specializations/machine-learning-introduction\n",
    "\n",
    "Working through that specialization is no small feat, but a whole world will open up to you if you can finish it. \n",
    "\n",
    "But for the purpose of this article, going into techinical detail about what numerical operations are performed will only cause confusion.\n",
    "\n",
    "**If reading my summaries of LLM processes is frustrating to you, that is a good thing**. It means you want a deeper understanding. The Coursera Specialization linked above will give you what you need - if you are willing to put in the time and effort.\n",
    "\n",
    "## Decoding: Numbers Back to Text\n",
    "Last stop, taking all the stuff we did with numbers and reverse the process used to encode text to numbers. Nothing particularly complicated here; however, Deep Learning engineers do have to consider how quickly and accurately *decoding* can be executed given the original *encoding* process.\n",
    "\n",
    "\n",
    "## What if I don't want to learn this stuff?\n",
    "Luckily, you don't have to. OpenAI and many other LLM companies make their money because people don't have the motivation and/or time to learn, build, implement, and use their own LLM.\n",
    "\n",
    "The primary way the 'monetize' LLMs is through their Application Programming (or Process) Interface (API). The API allows an end user to pass in text and receive the model output without understanding any deep learning.\n",
    "\n",
    "Below is an example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI API\n",
    "Basic config settings. Use API key from OpenAI to fine tune and run your own models\n",
    "\n",
    "Get API key from here (requires account): https://platform.openai.com/account/api-keys \n",
    "\n",
    "Note: OpenAIs API reference is... not good. https://platform.openai.com/docs/api-reference/ But you can guess the python methods as they generally correspond to the descriptions in documentation.\n",
    "\n",
    "For example, completion creation is `Completion.create()` and image creation is `Image.create()`\n",
    "\n",
    "Below is an example using the completion api. See other notebooks for more OpenAI examples:\n",
    "- Image Generation: https://github.com/thedanindanger/yaads-examples/blob/main/imageGeneration/imageGen.ipynb \n",
    "- Fine Tuning: https://github.com/thedanindanger/yaads-examples/tree/main/LinkedInPostAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Set the API Key\n",
    "key = open(\"../.config/openai.key\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import openai\n",
    "import pandas as pd\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_prompt = \"The first derivative of x^3+2 is:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = key\n",
    "\n",
    "response = openai.Completion.create(\n",
    "        model='text-davinci-003',\n",
    "        prompt= completion_prompt, #p,\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        stream=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x^2\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "## Try BLOOM and derivitatives: \n",
    "BLOOMZ trained BLOOM model: https://github.com/bigscience-workshop/xmtf#bloomz\n",
    "- how to download huggingface model: https://huggingface.co/docs/huggingface_hub/v0.13.3/guides/download\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2ed677225fe28fe8c7ce28c3636dbb1e2cdff49ecd1e58fa0656d75fd999a42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
